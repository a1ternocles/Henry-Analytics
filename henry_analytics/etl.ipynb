{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Transforming Load (ETL)\n",
    "\n",
    "En este notebook se planea procesar los datos encontrados en los archivos .csv. Con este fin vamos a usar distintas librerias que nos permitan obtener una base de datos limpia. Es de tener en cuenta que se usaran la menor cantidad de celdas de accion con el fin de hacer nuestro codigo lo mas corto y simple posible. De ser necesario, las interacciones tendran su respectivo comentario que nos ayudara a entender el codigo.\n",
    "\n",
    "Nuestro codigo se repartira en distintas secciones teniendo una similitud con el patron Modelo - Vista - Controlador (MVC):\n",
    "\n",
    "Celda de librerias.\n",
    "Celda de acciones.\n",
    "Celda de vistas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Librerias\n",
    "Esta Celda nos ayudara a traer todas las librerias necesarias con el fin de completar el ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias necesarias para el ejercicio\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Ignoramos los warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Acciones\n",
    "Esta celda nos ayudara a crear todas las funciones necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion que crea diccionarios para poder contar los tipos de datos que se encuentran en cada dataframe\n",
    "def diccionario_tipos_datos(dataframe_file):\n",
    "\n",
    "    dicc_col = {}\n",
    "    \n",
    "    for columna in dataframe_file:\n",
    "        conteo_tipos = dataframe_file[columna].apply(type).value_counts().to_dict()\n",
    "        dicc_col[columna] = {str(tipo): conteo for tipo, conteo in conteo_tipos.items()}\n",
    "\n",
    "    return dicc_col\n",
    "\n",
    "#Funcion que convierte los datos a flotantes si son numeros o ceros si son de otro tipo\n",
    "\n",
    "def cambio_a_float(dato):\n",
    "\n",
    "    if pd.isna(dato):\n",
    "        return 0.0\n",
    "    \n",
    "    try:\n",
    "        return float(dato)\n",
    "    except(ValueError, TypeError):\n",
    "        return 0.0\n",
    "\n",
    "#Funcion que convierte los datos a Datetime y devuelve None en caso de ser otro tipo\n",
    "\n",
    "def cambio_a_datetime(dato):\n",
    "\n",
    "    if pd.isna(dato):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        return pd.to_datetime(dato)\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vistas\n",
    "## 3.1. Obtencion de datos\n",
    "\n",
    "En esta seccion nos enfocamos en transformar los datos del formato original (.csv) a un formato Dataframe de pandas con el fin de poder observar, eliminar, transformar y demas procesos que nos permitan una mejor visualizacion y optimizacion de dichos datos.\n",
    "\n",
    "Los procesos a aplicar son:\n",
    "\n",
    "* Transformacion de .csv a Dataframe\n",
    "\n",
    "* Eliminacion y agregacion de columnas\n",
    "\n",
    "* Eliminacion de valores Null/Nan en los distintos Datasets\n",
    "\n",
    "* Reinicio de indices\n",
    "\n",
    "* Casting de datos a formatos correspondientes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.1 ETL para el Dataset: \"Internet_Penetracion.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carga completa del dataset: Internet_Penetracion.csv\n",
      "Caracteres cambiados en columnas: ['Accesos por cada 100 hogares', 'Accesos por cada 100 hab']\n",
      "Cambio format a float en columnas: ['Accesos por cada 100 hogares', 'Accesos por cada 100 hab']\n",
      "Datos vacios eliminados\n"
     ]
    }
   ],
   "source": [
    "#Carga del dataset\n",
    "inter_hogar = pd.read_csv(\"C:\\\\Users\\\\andre\\\\Documents\\\\Py Codes\\\\data\\\\Internet_Penetracion.csv\", sep=\",\")\n",
    "print(\"Carga completa del dataset: Internet_Penetracion.csv\")\n",
    "\n",
    "#Remplazo de \",\" a \".\" en columnas: Accesos por cada 100 hogares; Accesos por cada 100 hab\n",
    "col_trabajar = [\"Accesos por cada 100 hogares\",\"Accesos por cada 100 hab\"]\n",
    "inter_hogar[\"Accesos por cada 100 hogares\"] = inter_hogar[\"Accesos por cada 100 hogares\"].str.replace(\",\", \".\")\n",
    "inter_hogar[\"Accesos por cada 100 hab\"] = inter_hogar[\"Accesos por cada 100 hab\"].str.replace(\",\", \".\")\n",
    "print(f\"Caracteres cambiados en columnas: {col_trabajar}\")\n",
    "\n",
    "#Casting str a float\n",
    "inter_hogar[\"Accesos por cada 100 hogares\"] = inter_hogar[\"Accesos por cada 100 hogares\"].apply(cambio_a_float)\n",
    "inter_hogar[\"Accesos por cada 100 hab\"] = inter_hogar[\"Accesos por cada 100 hab\"].apply(cambio_a_float)\n",
    "print(f\"Cambio format a float en columnas: {col_trabajar}\")\n",
    "\n",
    "#Borrado de datos null\n",
    "inter_hogar.dropna(inplace=True)\n",
    "print(\"Datos vacios eliminados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.2 ETL para el Dataset: \"Internet_BAF.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna: Total modificada\n",
      "Datos vacios eliminados\n"
     ]
    }
   ],
   "source": [
    "#Carga del dataset\n",
    "inter_tech = pd.read_csv(\"C:\\\\Users\\\\andre\\\\Documents\\\\Py Codes\\\\data\\\\Internet_BAF.csv\",sep=\",\")\n",
    "\n",
    "#Modificacion de la col \"total\"\n",
    "inter_tech.drop(columns=\"Total\", inplace=True)\n",
    "inter_tech[\"total\"] = inter_tech[\"Banda ancha fija\"] + inter_tech[\"Dial up\"]\n",
    "print(\"Columna: Total modificada\")\n",
    "\n",
    "#Borrado de datos null\n",
    "inter_tech.dropna(inplace=True)\n",
    "print(\"Datos vacios eliminados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.3 ETL para el Dataset: \"Internet_Accesos-por-conectividad.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cambio a Format int en columnas: ['Año', 'Trimestre']\n",
      "Columna: Total Modificada\n",
      "Datos vacios eliminados\n"
     ]
    }
   ],
   "source": [
    "#Carga del dataset\n",
    "inter_acess = pd.read_csv(\"C:\\\\Users\\\\andre\\\\Documents\\\\Py Codes\\\\data\\\\Internet_Accesos-por-conectividad.csv\",sep=\",\")\n",
    "\n",
    "#Casting a Int a diferentes columnas\n",
    "\n",
    "col_trabajar = [\"Año\", \"Trimestre\"]\n",
    "inter_acess[\"Año\"] = inter_acess[\"Año\"].apply(cambio_a_float).astype(int)\n",
    "inter_acess[\"Trimestre\"] = inter_acess[\"Trimestre\"].apply(cambio_a_float).astype(int)\n",
    "print(f\"Cambio a Format int en columnas: {col_trabajar}\")\n",
    "\n",
    "#Modificacion columna \"Total\"\n",
    "inter_acess.drop(columns=\"Total\",inplace=True)\n",
    "inter_acess[\"Total\"] = inter_acess[\"ADSL\"] + inter_acess[\"Cablemodem\"] + inter_acess[\"Fibra óptica\"] + inter_acess[\"Wireless\"]+ inter_acess[\"Otros\"]\n",
    "print(f\"Columna: Total Modificada\")\n",
    "\n",
    "#Borrado de datos null\n",
    "inter_acess.dropna(inplace=True)\n",
    "print(\"Datos vacios eliminados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Revision Tipo de Datos\n",
    "\n",
    "Con la funcion definida anterior como \"diccionario_tipos_datos(dataframe_file)\" revisamos los tipos de datos que tienen cada una de las columnas dentro de nuestras bases de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Año': {\"<class 'int'>\": 36},\n",
       " 'Trimestre': {\"<class 'int'>\": 36},\n",
       " 'Accesos por cada 100 hogares': {\"<class 'float'>\": 36},\n",
       " 'Accesos por cada 100 hab': {\"<class 'float'>\": 36},\n",
       " 'Periodo': {\"<class 'str'>\": 36}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario_tipos_datos(inter_hogar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Año': {\"<class 'int'>\": 862},\n",
       " 'Trimestre': {\"<class 'int'>\": 862},\n",
       " 'Provincia': {\"<class 'str'>\": 862},\n",
       " 'Banda ancha fija': {\"<class 'int'>\": 862},\n",
       " 'Dial up': {\"<class 'float'>\": 862},\n",
       " 'total': {\"<class 'float'>\": 862}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario_tipos_datos(inter_tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Año': {\"<class 'int'>\": 864},\n",
       " 'Trimestre': {\"<class 'int'>\": 864},\n",
       " 'Provincia': {\"<class 'str'>\": 864},\n",
       " 'ADSL': {\"<class 'float'>\": 864},\n",
       " 'Cablemodem': {\"<class 'float'>\": 864},\n",
       " 'Fibra óptica': {\"<class 'float'>\": 864},\n",
       " 'Wireless': {\"<class 'float'>\": 864},\n",
       " 'Otros': {\"<class 'float'>\": 864},\n",
       " 'Total': {\"<class 'float'>\": 864}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diccionario_tipos_datos(inter_acess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Actualizacion de Datasets\n",
    "\n",
    "En esta seccion actualizaremos los datasets trabajados. Esto nos permitira tener los datos en los formatos adecuados y limpios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Actualizado: inter_hogar\n",
      "Dataset Actualizado: inter_tech\n",
      "Dataset Actualizado: inter_acess\n"
     ]
    }
   ],
   "source": [
    "inter_hogar.to_csv(\"C:\\\\Users\\\\andre\\\\Documents\\\\Py Codes\\\\data\\\\Internet_Penetracion.csv\", index=False)\n",
    "print(\"Dataset Actualizado: inter_hogar\")\n",
    "\n",
    "inter_tech.to_csv(\"C:\\\\Users\\\\andre\\\\Documents\\\\Py Codes\\\\data\\\\Internet_BAF.csv\",index=False)\n",
    "print(\"Dataset Actualizado: inter_tech\")\n",
    "\n",
    "inter_acess.to_csv(\"C:\\\\Users\\\\andre\\\\Documents\\\\Py Codes\\\\data\\\\Internet_Accesos-por-conectividad.csv\",index=False)\n",
    "print(\"Dataset Actualizado: inter_acess\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
